model:
  task: "segmentation"
  backbone: "mae"
  decoder: "segformer"
  img_size: 96
  num_channels: 10
  num_frames: 2
  num_classes: 3
  patch_size: 8

dataset:
  name: "lem"
  validate: True
  batch_size: 32
  num_workers: 4
  data_dir: "/pgeoprj2/godeep/ewab/datasets/LEM"

solver:
  name: "adam"
  criterion: "dice"
  learning_rate: 1e-3
  weight_decay:
  warmup_epochs:
  max_epochs: 100
  dev_run: False # Set to True for a quick test run
  overfit_batches: False # Set to true to overfit one batch of the data

checkpoint:
  save_dir: "/pgeoprj2/godeep/ewab/experiments/lem_supervised"
  run_name: "mae_segformer_weighted"
  run_id:
  pretrain_weights: "/pgeoprj2/godeep/ewab/experiments/mae_pretrain/wandb/ckpt_mae/mae-epoch=389-train_loss=0.00.ckpt"
  ckpt_path: # "/pgeoprj2/godeep/ewab/experiments/lem_supervised/wandb/ckpt_mae_segformer_weighted/mae_segformer_weighted-epoch=93-train_loss=0.00.ckpt"
  save_checkpoint: True